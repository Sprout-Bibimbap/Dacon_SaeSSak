{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d08a261477491d894a0d279b0ad9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jwj51720\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jwj51720\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5ffa46dc6947718bfd37bf18187f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/336k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f12ef2fa3f4a8c8bc9c7a501b6dfa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/967k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acaccd10b563418095fabab6974a2566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\") # 모델 불러오기\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\") # 이 모델에서 사용한 Tokenizer. SentenceTransformer에선 필요 없음"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "정리하면 사전 학습된 BERT로부터 문장 벡터를 얻는 방법은 다음과 같이 세 가지가 있습니다.\n",
    "\n",
    "BERT의 [CLS] 토큰의 출력 벡터를 문장 벡터로 간주한다.\n",
    "BERT의 모든 단어의 출력 벡터에 대해서 평균 풀링을 수행한 벡터를 문장 벡터로 간주한다.\n",
    "BERT의 모든 단어의 출력 벡터에 대해서 맥스 풀링을 수행한 벡터를 문장 벡터로 간주한다.\n",
    "이때 평균 풀링을 하느냐와 맥스 풀링을 하느냐에 따라서 해당 문장 벡터가 가지는 의미는 다소 다른데, 평균 풀링을 얻은 문장 벡터의 경우에는 모든 단어의 의미를 반영하는 쪽에 가깝다면, 맥스 풀링을 얻은 문장 벡터의 경우에는 중요한 단어의 의미를 반영하는 쪽에 가깝습니다.  \n",
    "출처: https://wikidocs.net/156176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "허깅페이스의 SentenceTransformer 모델은 여러 모듈(예: Transformer, Pooling)을 결합하여 문장 임베딩을 생성한다.  \n",
    "출력에서 볼 수 있듯이 모듈 중 하나는 models.Transformer, 하나는 models.Pooling이다. 중괄호 안의 내용들을 내가 Custom하여 넣을 수 있다.  \n",
    "여기서 Pooling은 데이터를 통합해 줄이는 역할을 한다. [1,2,3,4,5]라는 Tensor가 있다면, Max Pooling을 거쳤을 때 5, Mean Pooling을 거쳤을 때 3이 되겠다.  \n",
    "Pooling 모듈의 기본 Pooling Setting에서 pooling_mode_mean_tokens: True인 것을 볼 수 있다.   \n",
    "즉, 내가 입력으로 준 token들은 각각 768차원의 임베딩이 되는데, 이들의 평균을 취하여 output으로 내겠다는 의미이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='snunlp/KR-SBERT-V40K-klueNLI-augSTS', vocab_size=40000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예시로 문장을 넣어보자.\n",
    "\n",
    "tokenizer # 이 Tokenizer의 CLS 토큰은 2번이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 19185, 18, 9770, 17353, 9651, 20797, 9023, 18, 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"안녕하세요. 저는 진학사에 다니고 있습니다.\" \n",
    "SEQ_LEN = 128\n",
    "token = tokenizer.encode(example, truncation=True, padding=False, add_special_tokens=True)\n",
    "token # 실제로 CLS 토큰이 맨 앞에 붙어 있는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode(example).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내가 넣은 input의 token은 [2, 19185, 18, 9770, 17353, 9651, 20797, 9023, 18, 3]인데, 실제로 model의 output으로는 (768,)의 1차원 array가 나왔다.  \n",
    "mean pooling이 되었기 때문이다.  \n",
    "그럼 한번 커스텀해보자. 난 모든 token의 embedding을 얻고 싶다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"snunlp/KR-SBERT-V40K-klueNLI-augSTS\"\n",
    "\n",
    "word_embedding_model = models.Transformer(model_name, max_seq_length=256)\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # pooling layer를 제거해버렸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.encode(example, output_value='token_embeddings')\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확실히 [10, 768]인 걸 보니 [2, 19185, 18, 9770, 17353, 9651, 20797, 9023, 18, 3] 10개 토큰의 embedding이 모두 나왔다.  \n",
    "저 중에서 가장 앞에 있는 것이 CLS 토큰의 임베딩일 것이다. 감성분석 Task는 CLS 토큰의 임베딩을 이진분류하는 것으로 유명하다.  \n",
    "그럼 실제로 저 것의 첫 번째 임베딩이 CLS 토큰의 것이 맞는지 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.0831,  1.5027,  0.3664, -0.9721, -0.5213, -0.7787, -0.1496, -0.0293,\n",
      "         1.0156,  1.2694])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_cls = result[0] # 가장 첫 번째 것만 취함\n",
    "print(is_cls[:10])\n",
    "is_cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer 모듈 로드\n",
    "word_embedding_model = models.Transformer(model_name, max_seq_length=256)\n",
    "\n",
    "# Pooling 모듈 설정\n",
    "pooling_model = models.Pooling(\n",
    "    word_embedding_dimension=word_embedding_model.get_word_embedding_dimension(),\n",
    "    pooling_mode_cls_token=True, # 이번엔 Pooling Layer에서 CLS TOKEN만 True로 바꾸었다.\n",
    "    pooling_mode_mean_tokens=False,\n",
    "    pooling_mode_max_tokens=False,\n",
    "    pooling_mode_mean_sqrt_len_tokens=False\n",
    ")\n",
    "\n",
    "# SentenceTransformer 모델 생성\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.0831187 ,  1.5026569 ,  0.36637175, -0.97212404, -0.52125424,\n",
       "       -0.7786592 , -0.14956649, -0.0293241 ,  1.0156176 ,  1.2694006 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = model.encode(example)\n",
    "result2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2522,  0.4800,  0.5320,  0.4377,  0.3840, -0.4570,  0.4511, -1.4776,\n",
      "         0.6831, -1.8406])\n",
      "[ 0.2521757   0.48002505  0.53199536  0.4376778   0.38397276 -0.456951\n",
      "  0.45110777 -1.4776334   0.68309206 -1.8406454 ]\n"
     ]
    }
   ],
   "source": [
    "print(is_cls[345: 355])\n",
    "print(result2[345: 355]) # 똑같은 게 보인다. 반올림 차이 때문에 숫자는 약간 다르지만 동일한 값을 의미한다는 것은 알겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 감성분석 Task를 수행할 것이라면 이 CLS 토큰의 임베딩 768차원 값을 가져다가 nn.linear로 2개 값으로 보내버리면 된다.   \n",
    "그리고 softmax를 취해 합을 1로 만들어준다. loss는 이진 분류니까 cross entropy를 사용하면 될 것이다.  \n",
    "그럼 우리의 경우는? nn.linear로 1개 값으로 보내버리면 되겠다. 그 값과 label(나이 점수)의 차이를 loss로 MSE, MAE, RMSE 등 loss function 설정하여 학습하면 끝이다.\n",
    "근데 CLS만 가지고 하는 게 더 성능이 좋은지, MEAN POOLING이나 MAX POOLING이 더 성능이 좋을지는 해봐야 알 것 같다.  \n",
    "마음대로 모델 구조를 바꾸면서 해보면 되겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에까지는 SentenceTransformer를 사용하는 방법이었다.  \n",
    "SentenceTransformer는 내가 Input 문장을 tokenizing 할 필요가 없고, pooling도 알아서 붙어 있다.  \n",
    "그래서 저건 문장을 임베딩하는 데에 많이 사용한다.  \n",
    "일반적으로는 아래 AutoTokenizer, AutoModel을 사용한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "model_name = \"snunlp/KR-SBERT-V40K-klueNLI-augSTS\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(40000, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jwj51720\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jwj51720\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jwj51720\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:960\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 960\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarn_if_padding_and_no_attention_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    961\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jwj51720\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:4339\u001b[0m, in \u001b[0;36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m   4336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   4338\u001b[0m \u001b[38;5;66;03m# Check only the first and last input IDs to reduce overhead.\u001b[39;00m\n\u001b[1;32m-> 4339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[0;32m   4340\u001b[0m     warn_string \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4341\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4342\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/troubleshooting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4343\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#incorrect-output-when-padding-tokens-arent-masked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4344\u001b[0m     )\n\u001b[0;32m   4346\u001b[0m     \u001b[38;5;66;03m# If the pad token is equal to either BOS, EOS, or SEP, we do not know whether the user should use an\u001b[39;00m\n\u001b[0;32m   4347\u001b[0m     \u001b[38;5;66;03m# attention_mask or not. In this case, we should still show a warning because this is a rare case.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "model(example) # 이제는 이러면 오류가 난다. tokenizing이 되지 않았기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "example = \"안녕하세요. 저는 진학사에 다니고 있습니다.\"\n",
    "inputs = tokenizer(example, return_tensors='pt', max_length=256, padding='max_length', truncation=True) # 위에서 본 것처럼 tokenizer 사용\n",
    "print(inputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2, 19185,    18,  9770, 17353,  9651, 20797,  9023,    18,     3,\n",
      "            0,     0,     0,     0,     0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "(print(inputs['input_ids'][0][:15]))\n",
    "(print(inputs['token_type_ids'][0][:15]))\n",
    "(print(inputs['attention_mask'][0][:15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_ids는 tokenizing 된 token을 의미한다. [2, 19185, 18, 9770, 17353, 9651, 20797, 9023, 18, 3]가 되겠다.  \n",
    "token_type_ids는 두 문장이 SEP TOKEN으로 연결되어 있을 때 사용하는 것이다. 보통 문장이 이어졌는지 아닌지 판단하는 TASK에서 사용한다.  \n",
    "attention_mask는 어디까지가 진짜 input이고 어디부터 padding인지 알려준다. 앞에 10개만 1이고 나머지 max_length까지는 0이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.last_hidden_state.shape)\n",
    "print(outputs.pooler_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2522,  0.4800,  0.5320,  0.4377,  0.3840, -0.4570,  0.4511, -1.4776,\n",
      "         0.6831, -1.8406], grad_fn=<SliceBackward0>)\n",
      "tensor([-0.0315,  0.5800,  1.4216,  0.4184, -0.0334,  0.2474,  1.2193, -1.4339,\n",
      "        -0.0507, -0.3206], grad_fn=<SliceBackward0>)\n",
      "tensor([ 0.6642, -0.0170,  1.0080,  0.3886,  0.4695,  0.0686,  0.3521, -0.6086,\n",
      "         0.0771, -1.0137], grad_fn=<SliceBackward0>)\n",
      "tensor([ 0.8463, -0.3370,  1.2979,  0.2406,  0.0878,  0.1245,  0.4178, -0.7133,\n",
      "         0.2221, -0.7483], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.last_hidden_state[0][0][345:355]) # CLS가 가장 앞에 있다. 아까 위에서 봤던 숫자와 동일하다.\n",
    "print(outputs.last_hidden_state[0][1][345:355]) # 이제부터는 진짜 토큰들\n",
    "print(outputs.last_hidden_state[0][-2][345:355]) # 패딩\n",
    "print(outputs.last_hidden_state[0][-1][345:355]) # 패딩 -> position이 다르기 때문에 다른 embedding이 나온다. Transformer의 Positional Encoding 참조."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model의 output은 last_hidden_state과 pooler_output로 이루어진다.  \n",
    "last_hidden_state은 Transformer 모델의 마지막 은닉층에서의 출력이다. \n",
    "우리가 위에서 얻었던 [10, 768]과 동일하다. 다만 여기서는 padding에 대한 embedding도 다 나오는 것이다.\n",
    "결국 모든 token의 embedding을 가지고 싶다면? AutoModel로 모델을 불러오거나, SentenceTransformer에서 Pooling 제외하고 Transformer 모듈만 쓰면 된다.  \n",
    "그리고 outputs.pooler_output은 CLS 토큰의 768 차원을 tanh 씌운 것이라고 한다. tanh 활성화 함수를 붙이는 게 감성분석 등의 task에서는 별로 좋지 않다고 한다.  \n",
    "따라서 outputs.pooler_output는 무시하고 last_hidden_state의 CLS embedding을 가져다 쓰는 게 나을 수 있다.  \n",
    "사실 classification 전용으로 AutoModelForSequenceClassification도 존재한다.   \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2) 이러면 끝이라고 한다. 세상이 좋아졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지 SentenceTransformer와 AutoTokenizer, AutoModel의 사용법을 알아보았다. 이제 파인튜닝 하면 끝이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
