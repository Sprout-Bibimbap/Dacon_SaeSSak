{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Type Token Ratio\n",
    "- 개요\n",
    "    - 유형 토큰 비율(TTR)은 언어적 다양성을 측정하는 방법으로, 고유 토큰의 비율을 총 토큰 수로 나눈 값으로 정의.\n",
    "    - 측정값은 0과 1 사이로 제한되며 텍스트에 반복이 없으면 이 측정값은 1이고 무한 반복이 있으면 0에 가까워짐.\n",
    "    - 토큰 수가 증가하면 TTR이 평평해지는 경향이 있으므로 길이가 다른 텍스트를 분석하는 경우에는 이 측정값을 권장하지는 않음.\n",
    "- 해석\n",
    "    - 텍스트나 문서의 TTR 값이 낮으면 기능어가 내용어보다 더 많다는 뜻.\n",
    "        - 기능어는 대명사, 전치사, 수정 동사와 같이 문장의 내용을 둘러싸는 역할을 하는 언어의 필러 단어\n",
    "    - TTR은 텍스트 복잡성 자체를 나타낼 수 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinhakai2/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"HF_API_KEY\")\n",
    "repo_id = \"SaeSSak/Conversation\"\n",
    "file_path = hf_hub_download(repo_id, \"FinalData.parquet\", repo_type=\"dataset\", use_auth_token=api_key)\n",
    "data = pd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen1 = \"화장실에 갈 때도 줄을 잘 서야 해요\"\n",
    "sen2 = \"밥 먹으러 가자\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. 접근 1: 어근의 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_tts(text):\n",
    "    tokens = okt.morphs(text)\n",
    "    roots = [okt.morphs(word, stem=True) for word in tokens]\n",
    "    flat_roots = [item for sublist in roots for item in sublist]\n",
    "    print(text)\n",
    "    print(tokens)\n",
    "    print(flat_roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "화장실에 갈 때도 줄을 잘 서야 해요\n",
      "['화장실', '에', '갈', '때', '도', '줄', '을', '잘', '서야', '해', '요']\n",
      "['화장실', '에', '갈다', '때', '도', '줄', '을', '자다', '서다', '해', '요']\n",
      "밥 먹으러 가자\n",
      "['밥', '먹으러', '가자']\n",
      "['밥', '먹다', '가다']\n"
     ]
    }
   ],
   "source": [
    "root_tts(sen1)\n",
    "root_tts(sen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['갈다']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.morphs(tokens[2], stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>음성인식결과</th>\n",
       "      <th>지역</th>\n",
       "      <th>성별</th>\n",
       "      <th>대화주제</th>\n",
       "      <th>나이</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>내일 또 얘기하자</td>\n",
       "      <td>수도권</td>\n",
       "      <td>여</td>\n",
       "      <td>학교</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>교복을 입고 왔어요</td>\n",
       "      <td>수도권</td>\n",
       "      <td>여</td>\n",
       "      <td>교복</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>나는 씩씩해요</td>\n",
       "      <td>수도권</td>\n",
       "      <td>여</td>\n",
       "      <td>소풍을 다녀와서</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>빨리 내일이 됐으면 좋겠다</td>\n",
       "      <td>수도권</td>\n",
       "      <td>여</td>\n",
       "      <td>삼촌댁에 놀러가기</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>같이 맞는 거야</td>\n",
       "      <td>수도권</td>\n",
       "      <td>여</td>\n",
       "      <td>삶과 죽음</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142358</th>\n",
       "      <td>나도 발레 배우는데</td>\n",
       "      <td>수도권</td>\n",
       "      <td>남</td>\n",
       "      <td>발레</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142359</th>\n",
       "      <td>유치원 때부터 배웠어</td>\n",
       "      <td>수도권</td>\n",
       "      <td>남</td>\n",
       "      <td>발레</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142360</th>\n",
       "      <td>다리를 모아야 돼</td>\n",
       "      <td>수도권</td>\n",
       "      <td>남</td>\n",
       "      <td>발레</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142361</th>\n",
       "      <td>무릎이 붙어야 하는 거야</td>\n",
       "      <td>수도권</td>\n",
       "      <td>남</td>\n",
       "      <td>발레</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142362</th>\n",
       "      <td>손을 위로 올리고 왼쪽 다리를 내밀어야 돼</td>\n",
       "      <td>수도권</td>\n",
       "      <td>남</td>\n",
       "      <td>발레</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1142363 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          음성인식결과   지역 성별       대화주제  나이\n",
       "0                      내일 또 얘기하자  수도권  여         학교   5\n",
       "1                     교복을 입고 왔어요  수도권  여         교복   5\n",
       "2                       나는 씩씩해요   수도권  여   소풍을 다녀와서   7\n",
       "3                빨리 내일이 됐으면 좋겠다   수도권  여  삼촌댁에 놀러가기   7\n",
       "4                       같이 맞는 거야  수도권  여      삶과 죽음   7\n",
       "...                          ...  ... ..        ...  ..\n",
       "1142358               나도 발레 배우는데  수도권  남         발레  10\n",
       "1142359              유치원 때부터 배웠어  수도권  남         발레  10\n",
       "1142360                다리를 모아야 돼  수도권  남         발레  10\n",
       "1142361            무릎이 붙어야 하는 거야  수도권  남         발레  10\n",
       "1142362  손을 위로 올리고 왼쪽 다리를 내밀어야 돼  수도권  남         발레  10\n",
       "\n",
       "[1142363 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TTR 계산 함수\n",
    "def calculate_ttr(text):\n",
    "    okt = Okt()\n",
    "    tokens = okt.morphs(text)\n",
    "    unique_tokens = set(tokens)\n",
    "    return len(unique_tokens) / len(tokens) if tokens else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. HD-D (Hypergeometric Distribution D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from scipy.stats import hypergeom\n",
    "import numpy as np\n",
    "\n",
    "# 텍스트 샘플\n",
    "text = \"\"\"\n",
    "Hypergeometric Distribution D (HDD)는 각 단어의 텍스트 내 등장 빈도와 텍스트의 길이를 기반으로 어휘 다양성을 계산하는 방법입니다. HDD는 특히 다양한 길이의 텍스트에서 일관된 측정을 제공합니다.\n",
    "\n",
    "HDD를 계산하는 기본 원리는 다음과 같습니다: 각 단어에 대해, 만약 단어가 텍스트에서 무작위로 선택된 n개의 단어 중 하나라면, 그 단어가 적어도 한 번 나타날 확률을 계산합니다. 이러한 확률들의 합은 전체 텍스트의 어휘 다양성을 나타냅니다.\n",
    "\n",
    "Python으로 HDD를 구현하는 예제를 제공하겠습니다. 이 예제에서는 nltk 라이브러리를 사용하여 텍스트를 토큰화하고 빈도를 계산합니다. scipy 라이브러리의 hypergeom 모듈을 사용하여 필요한 확률을 계산합니다.\n",
    "\"\"\"\n",
    "\n",
    "# 토큰화 및 빈도 분석\n",
    "tokens = nltk.word_tokenize(text)\n",
    "fdist = FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDD 값: 8.732897548968863\n"
     ]
    }
   ],
   "source": [
    "N = len(tokens)\n",
    "n = N // 10  # 예를 들어, 텍스트 길이의 약 10%를 샘플 크기로 설정\n",
    "hdd = sum(hypergeom.sf(0, N, fdist[word], n) for word in fdist)\n",
    "\n",
    "print(f\"HDD 값: {hdd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MTLD (Measure of Textual Lexical Diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from scipy.stats import hypergeom\n",
    "import numpy as np\n",
    "\n",
    "# 텍스트 샘플\n",
    "text = \"화장실에 갈 때도 줄을 잘 서야 해요. 화장실을 사용할 때는 질서를 지키는 것이 중요합니다.\"\n",
    "\n",
    "# 토큰화 및 빈도 분석\n",
    "tokens = nltk.word_tokenize(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
