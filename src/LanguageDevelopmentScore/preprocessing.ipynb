{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 제작(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_json_files(folder_path):\n",
    "    # Initialize an empty list to store data\n",
    "    data_list = []\n",
    "    \n",
    "    # Walk through all subdirectories and files\n",
    "    for root, dirs, files in tqdm(os.walk(folder_path)):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                # Construct the full file path\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Open and read the JSON file\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # Append the data to the list\n",
    "                data_list.append(data)\n",
    "    \n",
    "    # Normalize the JSON data\n",
    "    df = pd.json_normalize(data_list, sep='_')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. AI챗봇\n",
    "\n",
    "# Example folder path (replace with the actual folder path)\n",
    "folder_path = r\"C:\\Users\\jwj51720\\Desktop\\장원준\\Dacon_SaeSSak\\data\\자유대화 음성(소아, 유아)\\Validation\\[라벨]1.AI챗봇\"\n",
    "\n",
    "# Process the JSON files and create the DataFrame\n",
    "result_df = process_json_files(folder_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.columns)\n",
    "result_df.columns = [\n",
    "    '음성인식결과',\n",
    "    '스크립트ID',\n",
    "    '파일명',\n",
    "    '녹음시간',\n",
    "    '녹음품질',\n",
    "    '녹음일시',\n",
    "    '스크립트셋번호',\n",
    "    '녹음환경',\n",
    "    '수집방법',\n",
    "    '지역',\n",
    "    '녹음도구',\n",
    "    '대화주제',\n",
    "    '성별',\n",
    "    '녹음자ID',\n",
    "    '나이'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"./data/val_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 음성수집도구\n",
    "\n",
    "# Example folder path (replace with the actual folder path)\n",
    "folder_path = r\"C:\\Users\\jwj51720\\Desktop\\장원준\\Dacon_SaeSSak\\data\\자유대화 음성(소아, 유아)\\Validation\\[라벨]2.음성수집도구\"\n",
    "\n",
    "# Process the JSON files and create the DataFrame\n",
    "result_df = process_json_files(folder_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.columns)\n",
    "result_df.columns = [\n",
    "    '음성인식결과',\n",
    "    '스크립트ID',\n",
    "    '파일명',\n",
    "    '녹음시간',\n",
    "    '녹음품질',\n",
    "    '녹음일시',\n",
    "    '스크립트셋번호',\n",
    "    '녹음환경',\n",
    "    '수집방법',\n",
    "    '지역',\n",
    "    '녹음도구',\n",
    "    '대화주제',\n",
    "    '성별',\n",
    "    '녹음자ID',\n",
    "    '나이'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"./data/val_data2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 스튜디오\n",
    "\n",
    "# Example folder path (replace with the actual folder path)\n",
    "folder_path = r\"C:\\Users\\jwj51720\\Desktop\\장원준\\Dacon_SaeSSak\\data\\자유대화 음성(소아, 유아)\\Validation\\[라벨]3.스튜디오\"\n",
    "\n",
    "# Process the JSON files and create the DataFrame\n",
    "result_df = process_json_files(folder_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.columns)\n",
    "result_df.columns = [\n",
    "    '음성인식결과',\n",
    "    '스크립트ID',\n",
    "    '파일명',\n",
    "    '녹음시간',\n",
    "    '녹음품질',\n",
    "    '녹음일시',\n",
    "    '스크립트셋번호',\n",
    "    '녹음환경',\n",
    "    '수집방법',\n",
    "    '지역',\n",
    "    '녹음도구',\n",
    "    '대화주제',\n",
    "    '성별',\n",
    "    '녹음자ID',\n",
    "    '나이'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"./data/val_data3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1 데이터 Load 및 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./data/val_data.csv\")\n",
    "df2 = pd.read_csv(\"./data/val_data2.csv\")\n",
    "df3 = pd.read_csv(\"./data/val_data3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df1))\n",
    "print(len(df2))\n",
    "print(len(df3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1.head(3))\n",
    "display(df2.head(3))\n",
    "display(df3.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.astype({\n",
    "    '음성인식결과': 'string',\n",
    "    '스크립트ID': 'string',\n",
    "    '파일명': 'string',\n",
    "    \"녹음시간\": \"float32\",\n",
    "    \"녹음품질\": \"string\",\n",
    "    \"녹음일시\": \"string\",\n",
    "    \"스크립트셋번호\": \"string\",\n",
    "    \"녹음환경\": \"string\",\n",
    "    \"수집방법\": \"string\",\n",
    "    \"지역\": \"string\",\n",
    "    \"녹음도구\": \"string\",\n",
    "    \"대화주제\": \"string\",\n",
    "    \"성별\": \"string\",\n",
    "    \"녹음자ID\": \"string\",\n",
    "    \"나이\": \"int32\"\n",
    "})\n",
    "df.to_csv(\"./data/validation.csv\", index=False)\n",
    "df.to_parquet(\"./data/validation.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(len(df.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음성인식결과는 INPUT\n",
    "print(df[\"음성인식결과\"].value_counts())\n",
    "df[df[\"음성인식결과\"] == \"다음 이 시간 뭐야 음악이야\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지역과 성별은 좋은 힌트가 될 수도... 말투의 변화나 관심사의 변호가 있을 수 있음.\n",
    "print(df[\"지역\"].value_counts()) # 수도권에 집중되어 있음\n",
    "print(df[\"성별\"].value_counts()) # 거의 비슷한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 대화주제는 아이가 주제에 얼마나 잘 맞추는지를 평가할 수 있는 지표가 될 수 있음\n",
    "# 집중력? 같은 지표로 제시 가능\n",
    "print(df[\"대화주제\"].value_counts()) # 1201개나 존재\n",
    "\n",
    "def plot_value_counts(value_counts):\n",
    "    # Sort the value counts\n",
    "    sorted_counts = value_counts.sort_values(ascending=False)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.bar(range(len(sorted_counts)), sorted_counts)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Categories')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title('Value Counts Distribution')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "plot_value_counts(df[\"대화주제\"].value_counts()) # 특정 주제에 집중되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이는 OUTPUT LABEL\n",
    "df[\"나이\"].value_counts() # 3세 데이터가 많지는 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. 데이터 허깅페이스에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원본 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"HF_API_KEY\")\n",
    "api = HfApi()\n",
    "repo_id = \"SaeSSak/Conversation\"\n",
    "file_in_repo = \"ValidOriginalData.parquet\"\n",
    "\n",
    "# 기존 파일 삭제\n",
    "api.delete_file(\n",
    "    path_in_repo=file_in_repo,\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    "    token=api_key\n",
    ")\n",
    "\n",
    "# 다시 올리기\n",
    "api.upload_file(\n",
    "        path_or_fileobj=\"data/validation.parquet\", # Local 데이터 경로\n",
    "        path_in_repo=file_in_repo, # Repo에 저장하고자 하는 이름 (parquet 권장)\n",
    "        repo_id=repo_id, # 저장소 이름\n",
    "        repo_type=\"dataset\", # 저장소의 Type\n",
    "        token=api_key # 나의 API 키\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필요한 데이터만 추출 & 허깅페이스에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[[\"음성인식결과\", \"지역\", \"성별\", \"대화주제\", \"나이\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df2))\n",
    "print(len(df2.drop_duplicates()))\n",
    "df = df2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/validation_preprocessing.csv\", index=False)\n",
    "df.to_parquet(\"./data/validation_preprocessing.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"HF_API_KEY\")\n",
    "api = HfApi()\n",
    "repo_id = \"SaeSSak/Conversation\"\n",
    "file_in_repo = \"ValidPreprocessedData.parquet\"\n",
    "\n",
    "# 기존 파일 삭제\n",
    "api.delete_file(\n",
    "    path_in_repo=file_in_repo,\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    "    token=api_key\n",
    ")\n",
    "\n",
    "api.upload_file(\n",
    "        path_or_fileobj=\"data/validation_preprocessing.parquet\", # Local 데이터 경로\n",
    "        path_in_repo=file_in_repo, # Repo에 저장하고자 하는 이름 (parquet 권장)\n",
    "        repo_id=repo_id, # 저장소 이름\n",
    "        repo_type=\"dataset\", # 저장소의 Type\n",
    "        token=api_key # 나의 API 키\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"HF_API_KEY\")\n",
    "\n",
    "repo_id = \"SaeSSak/Conversation\"\n",
    "file_path = hf_hub_download(repo_id, \"PreprocessedData.parquet\", repo_type=\"dataset\", use_auth_token=api_key)\n",
    "\n",
    "# 파일 로드\n",
    "df = pd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4. 특수문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(r'[^\\w\\s]', re.UNICODE)\n",
    "filtered_df = df[df[\"음성인식결과\"].str.contains(pattern)]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters_and_brackets(text):\n",
    "    # 괄호와 괄호 안의 내용을 제거\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    # 특수문자 제거 (공백과 알파벳, 숫자, 한글만 남김)\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['정제된_결과'] = df['음성인식결과'].apply(remove_special_characters_and_brackets)\n",
    "df[df[\"음성인식결과\"].str.contains(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('', None).dropna(subset=['정제된_결과'])\n",
    "df[df[\"음성인식결과\"].str.contains(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"음성인식결과\"] = df[\"정제된_결과\"]\n",
    "df = df.drop(columns=[\"정제된_결과\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../../data/validation_preprocessing_v2.parquet\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"HF_API_KEY\")\n",
    "api = HfApi()\n",
    "repo_id = \"SaeSSak/Conversation\"\n",
    "file_in_repo = \"ValidPreprocessedDataClean.parquet\"\n",
    "\n",
    "api.upload_file(\n",
    "        path_or_fileobj=\"../../data/validation_preprocessing_v2.parquet\", # Local 데이터 경로\n",
    "        path_in_repo=file_in_repo, # Repo에 저장하고자 하는 이름 (parquet 권장)\n",
    "        repo_id=repo_id, # 저장소 이름\n",
    "        repo_type=\"dataset\", # 저장소의 Type\n",
    "        token=api_key # 나의 API 키\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 제작(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def unzip_file(zip_path, extract_to):\n",
    "    \"\"\"\n",
    "    지정된 zip 파일을 열고 모든 파일을 주어진 디렉토리에 압축 해제합니다.\n",
    "    \n",
    "    Args:\n",
    "    zip_path (str): 압축 해제할 zip 파일의 경로.\n",
    "    extract_to (str): 파일을 압축 해제할 대상 폴더의 경로.\n",
    "    \"\"\"\n",
    "    # 해당 디렉토리가 존재하지 않으면 생성\n",
    "    if not os.path.exists(extract_to):\n",
    "        os.makedirs(extract_to)\n",
    "\n",
    "    # Zip 파일 열기\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        # Zip 내용 압축 해제\n",
    "        zip_ref.extractall(extract_to)\n",
    "        print(f\"Files extracted to: {extract_to}\")\n",
    "\n",
    "# 사용 예\n",
    "zip_path = 'data/[라벨]1.AI챗봇.zip'\n",
    "extract_to = 'data/[라벨]1.AI챗봇'\n",
    "\n",
    "unzip_file(zip_path, extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = \"data/[라벨]2.음성수집도구.zip\"\n",
    "extract_to = 'data/[라벨]2.음성수집도구'\n",
    "unzip_file(zip_path, extract_to)\n",
    "\n",
    "zip_path = \"data/[라벨]3.스튜디오.zip\"\n",
    "extract_to = 'data/[라벨]3.스튜디오'\n",
    "unzip_file(zip_path, extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_json_files(folder_path):\n",
    "    # Initialize an empty list to store data\n",
    "    data_list = []\n",
    "    \n",
    "    # Walk through all subdirectories and files\n",
    "    for root, dirs, files in tqdm(os.walk(folder_path)):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                # Construct the full file path\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Open and read the JSON file\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # Append the data to the list\n",
    "                data_list.append(data)\n",
    "    \n",
    "    # Normalize the JSON data\n",
    "    df = pd.json_normalize(data_list, sep='_')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. AI챗봇\n",
    "\n",
    "# Example folder path (replace with the actual folder path)\n",
    "folder_path = r\"data/[라벨]1.AI챗봇\"\n",
    "\n",
    "# Process the JSON files and create the DataFrame\n",
    "result_df = process_json_files(folder_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.columns)\n",
    "result_df.columns = [\n",
    "    '음성인식결과',\n",
    "    '스크립트ID',\n",
    "    '파일명',\n",
    "    '녹음시간',\n",
    "    '녹음품질',\n",
    "    '녹음일시',\n",
    "    '스크립트셋번호',\n",
    "    '녹음환경',\n",
    "    '수집방법',\n",
    "    '지역',\n",
    "    '녹음도구',\n",
    "    '대화주제',\n",
    "    '성별',\n",
    "    '녹음자ID',\n",
    "    '나이'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"./data/train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 음성수집도구\n",
    "\n",
    "# Example folder path (replace with the actual folder path)\n",
    "folder_path = r\"data/[라벨]2.음성수집도구\"\n",
    "\n",
    "# Process the JSON files and create the DataFrame\n",
    "result_df = process_json_files(folder_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.columns)\n",
    "result_df.columns = [\n",
    "    '음성인식결과',\n",
    "    '스크립트ID',\n",
    "    '파일명',\n",
    "    '녹음시간',\n",
    "    '녹음품질',\n",
    "    '녹음일시',\n",
    "    '스크립트셋번호',\n",
    "    '녹음환경',\n",
    "    '수집방법',\n",
    "    '지역',\n",
    "    '녹음도구',\n",
    "    '대화주제',\n",
    "    '성별',\n",
    "    '녹음자ID',\n",
    "    '나이'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"./data/train_data2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 스튜디오\n",
    "\n",
    "# Example folder path (replace with the actual folder path)\n",
    "folder_path = r\"data/[라벨]3.스튜디오\"\n",
    "\n",
    "# Process the JSON files and create the DataFrame\n",
    "result_df = process_json_files(folder_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.columns)\n",
    "result_df.columns = [\n",
    "    '음성인식결과',\n",
    "    '스크립트ID',\n",
    "    '파일명',\n",
    "    '녹음시간',\n",
    "    '녹음품질',\n",
    "    '녹음일시',\n",
    "    '스크립트셋번호',\n",
    "    '녹음환경',\n",
    "    '수집방법',\n",
    "    '지역',\n",
    "    '녹음도구',\n",
    "    '대화주제',\n",
    "    '성별',\n",
    "    '녹음자ID',\n",
    "    '나이'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"./data/train_data3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. 데이터 Load 및 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./data/train_data.csv\")\n",
    "df2 = pd.read_csv(\"./data/train_data2.csv\")\n",
    "df3 = pd.read_csv(\"./data/train_data3.csv\")\n",
    "\n",
    "print(len(df1))\n",
    "print(len(df2))\n",
    "print(len(df3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({\n",
    "    '음성인식결과': 'string',\n",
    "    '스크립트ID': 'string',\n",
    "    '파일명': 'string',\n",
    "    \"녹음시간\": \"float32\",\n",
    "    \"녹음품질\": \"string\",\n",
    "    \"녹음일시\": \"string\",\n",
    "    \"스크립트셋번호\": \"string\",\n",
    "    \"녹음환경\": \"string\",\n",
    "    \"수집방법\": \"string\",\n",
    "    \"지역\": \"string\",\n",
    "    \"녹음도구\": \"string\",\n",
    "    \"대화주제\": \"string\",\n",
    "    \"성별\": \"string\",\n",
    "    \"녹음자ID\": \"string\",\n",
    "    \"나이\": \"int32\"\n",
    "})\n",
    "df.to_csv(\"./data/train.csv\", index=False)\n",
    "df.to_parquet(\"./data/train.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(len(df.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지역과 성별은 좋은 힌트가 될 수도... 말투의 변화나 관심사의 변호가 있을 수 있음.\n",
    "print(df[\"지역\"].value_counts()) # 수도권에 집중되어 있음\n",
    "print(df[\"성별\"].value_counts()) # 거의 비슷한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"나이\"].value_counts() # 3세 데이터가 많지는 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. 데이터 허깅페이스에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원본 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"HF_API_KEY\")\n",
    "api = HfApi()\n",
    "repo_id = \"SaeSSak/Conversation\"\n",
    "file_in_repo = \"TrainOriginalData.parquet\"\n",
    "\n",
    "api.delete_file(\n",
    "    path_in_repo=file_in_repo,\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    "    token=api_key\n",
    ")\n",
    "\n",
    "# 다시 올리기\n",
    "api.upload_file(\n",
    "        path_or_fileobj=\"data/train.parquet\", # Local 데이터 경로\n",
    "        path_in_repo=file_in_repo, # Repo에 저장하고자 하는 이름 (parquet 권장)\n",
    "        repo_id=repo_id, # 저장소 이름\n",
    "        repo_type=\"dataset\", # 저장소의 Type\n",
    "        token=api_key # 나의 API 키\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필요한 데이터만 추출 & 허깅페이스에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[[\"음성인식결과\", \"지역\", \"성별\", \"대화주제\", \"나이\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df2))\n",
    "print(len(df2.drop_duplicates()))\n",
    "df = df2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/train_preprocessing.csv\", index=False)\n",
    "df.to_parquet(\"./data/train_preprocessing.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"HF_API_KEY\")\n",
    "api = HfApi()\n",
    "repo_id = \"SaeSSak/Conversation\"\n",
    "file_in_repo = \"TrainPreprocessedData.parquet\"\n",
    "\n",
    "api.upload_file(\n",
    "        path_or_fileobj=\"data/train_preprocessing.parquet\", # Local 데이터 경로\n",
    "        path_in_repo=file_in_repo, # Repo에 저장하고자 하는 이름 (parquet 권장)\n",
    "        repo_id=repo_id, # 저장소 이름\n",
    "        repo_type=\"dataset\", # 저장소의 Type\n",
    "        token=api_key # 나의 API 키\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. 특수문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_special_characters_and_brackets(text):\n",
    "    # 괄호와 괄호 안의 내용을 제거\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    # 특수문자 제거 (공백과 알파벳, 숫자, 한글만 남김)\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['정제된_결과'] = df['음성인식결과'].apply(remove_special_characters_and_brackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('', None).dropna(subset=['정제된_결과'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"음성인식결과\"] = df[\"정제된_결과\"]\n",
    "df = df.drop(columns=[\"정제된_결과\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"./data/train_preprocessing_v2.parquet\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"HF_API_KEY\")\n",
    "api = HfApi()\n",
    "repo_id = \"SaeSSak/Conversation\"\n",
    "file_in_repo = \"TrainPreprocessedDataClean.parquet\"\n",
    "\n",
    "# api.delete_file(\n",
    "#     path_in_repo=file_in_repo,\n",
    "#     repo_id=repo_id,\n",
    "#     repo_type=\"dataset\",\n",
    "#     token=api_key\n",
    "# )\n",
    "\n",
    "\n",
    "api.upload_file(\n",
    "        path_or_fileobj=\"./data/train_preprocessing_v2.parquet\", # Local 데이터 경로\n",
    "        path_in_repo=file_in_repo, # Repo에 저장하고자 하는 이름 (parquet 권장)\n",
    "        repo_id=repo_id, # 저장소 이름\n",
    "        repo_type=\"dataset\", # 저장소의 Type\n",
    "        token=api_key # 나의 API 키\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Trian + valid 결합 및 Test set 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"HF_API_KEY\")\n",
    "\n",
    "repo_id = \"SaeSSak/Conversation\"\n",
    "file_path = hf_hub_download(repo_id, \"TrainPreprocessedDataClean.parquet\", repo_type=\"dataset\", use_auth_token=api_key)\n",
    "\n",
    "# 파일 로드\n",
    "train = pd.read_parquet(file_path)\n",
    "\n",
    "file_path = hf_hub_download(repo_id, \"ValidPreprocessedDataClean.parquet\", repo_type=\"dataset\", use_auth_token=api_key)\n",
    "\n",
    "# 파일 로드\n",
    "valid = pd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(valid.head(3))\n",
    "display(train.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, valid], axis = 0)\n",
    "df = df.reset_index(drop=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.plot(df[\"나이\"].value_counts().sort_values(key= lambda x: x.index, ascending=False))\n",
    "plt.plot(np.log1p(df[\"나이\"]).value_counts().sort_values(key= lambda x: x.index, ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이 3부터 10까지 각각 10개씩 샘플링하여 결합\n",
    "sampled_df_list = []\n",
    "sampled_indices = []\n",
    "\n",
    "for age in range(3, 11):\n",
    "    sampled_df = df[df['나이'] == age].sample(n=10, random_state=3, replace=True)\n",
    "    sampled_df_list.append(sampled_df)\n",
    "    sampled_indices.extend(sampled_df.index)\n",
    "\n",
    "# 샘플링된 데이터프레임 결합\n",
    "result_df = pd.concat(sampled_df_list, ignore_index=True)\n",
    "\n",
    "# 원본 데이터프레임에서 샘플링된 행 제거\n",
    "df_dropped = df.drop(index=sampled_indices)\n",
    "print(len(result_df), len(df_dropped))\n",
    "result_df.to_parquet(\"./data/test.parquet\", index=False)\n",
    "df_dropped.to_parquet(\"./data/all.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"HF_API_KEY\")\n",
    "api = HfApi()\n",
    "repo_id = \"SaeSSak/Conversation\"\n",
    "file_in_repo = \"FinalData.parquet\"\n",
    "\n",
    "# 다시 올리기\n",
    "api.upload_file(\n",
    "        path_or_fileobj=\"./data/all.parquet\", # Local 데이터 경로\n",
    "        path_in_repo=file_in_repo, # Repo에 저장하고자 하는 이름 (parquet 권장)\n",
    "        repo_id=repo_id, # 저장소 이름\n",
    "        repo_type=\"dataset\", # 저장소의 Type\n",
    "        token=api_key # 나의 API 키\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"HF_API_KEY\")\n",
    "api = HfApi()\n",
    "repo_id = \"SaeSSak/Conversation\"\n",
    "file_in_repo = \"TestData.parquet\"\n",
    "\n",
    "# 다시 올리기\n",
    "api.upload_file(\n",
    "        path_or_fileobj=\"./data/test.parquet\", # Local 데이터 경로\n",
    "        path_in_repo=file_in_repo, # Repo에 저장하고자 하는 이름 (parquet 권장)\n",
    "        repo_id=repo_id, # 저장소 이름\n",
    "        repo_type=\"dataset\", # 저장소의 Type\n",
    "        token=api_key # 나의 API 키\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 불균형 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinhakai2/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"HF_API_KEY\")\n",
    "repo_id = \"SaeSSak/Conversation\"\n",
    "file_path = hf_hub_download(repo_id, \"FinalData.parquet\", repo_type=\"dataset\", use_auth_token=api_key)\n",
    "\n",
    "# 파일 로드\n",
    "df = pd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"output\":\"나이\"}\n",
    "data = df\n",
    "label_counts = data[config[\"output\"]].value_counts()\n",
    "min_count = label_counts.min()\n",
    "resampled_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23396\n",
      "23396\n",
      "23396\n",
      "23396\n",
      "23396\n",
      "23396\n",
      "23396\n",
      "23396\n"
     ]
    }
   ],
   "source": [
    "for label in label_counts.index:\n",
    "    label_data = data[data[config[\"output\"]] == label]\n",
    "    resampled_label_data = label_data.sample(min_count, replace=False)\n",
    "    resampled_data = pd.concat(\n",
    "                [resampled_data, resampled_label_data], ignore_index=True\n",
    "            )\n",
    "    print(len(resampled_label_data))\n",
    "data1 = resampled_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>음성인식결과</th>\n",
       "      <th>지역</th>\n",
       "      <th>성별</th>\n",
       "      <th>대화주제</th>\n",
       "      <th>나이</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>동생이 우유 먹다 흘렸어</td>\n",
       "      <td>수도권</td>\n",
       "      <td>여</td>\n",
       "      <td>동생 돌보기</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>잠이 와요</td>\n",
       "      <td>전라</td>\n",
       "      <td>남</td>\n",
       "      <td>소풍</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>준서가 다리 다쳤대</td>\n",
       "      <td>수도권</td>\n",
       "      <td>여</td>\n",
       "      <td>친구에 대해 말하기</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>내가 학교 끝나고 진성이랑 사 먹을게</td>\n",
       "      <td>수도권</td>\n",
       "      <td>여</td>\n",
       "      <td>길거리 음식</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>목사님이 잘 하는 사람 선물 준대</td>\n",
       "      <td>전라</td>\n",
       "      <td>남</td>\n",
       "      <td>크리스마스</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374331</th>\n",
       "      <td>그러니까 이제 더 아프면 안돼 약속해</td>\n",
       "      <td>경상</td>\n",
       "      <td>여</td>\n",
       "      <td>엄마가 아파요</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374332</th>\n",
       "      <td>머리가 어지러워</td>\n",
       "      <td>경상</td>\n",
       "      <td>여</td>\n",
       "      <td>공부</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374333</th>\n",
       "      <td>아 빗나갔다</td>\n",
       "      <td>강원</td>\n",
       "      <td>남</td>\n",
       "      <td>오락실 게임</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374334</th>\n",
       "      <td>수민이가 이사가서 서운해요</td>\n",
       "      <td>수도권</td>\n",
       "      <td>남</td>\n",
       "      <td>친구</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374335</th>\n",
       "      <td>난 거북이를 키우고 싶</td>\n",
       "      <td>수도권</td>\n",
       "      <td>남</td>\n",
       "      <td>거북이</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374336 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       음성인식결과   지역 성별        대화주제  나이\n",
       "0               동생이 우유 먹다 흘렸어  수도권  여      동생 돌보기  10\n",
       "1                       잠이 와요   전라  남          소풍   6\n",
       "2                 준서가 다리 다쳤대   수도권  여  친구에 대해 말하기   9\n",
       "3       내가 학교 끝나고 진성이랑 사 먹을게   수도권  여      길거리 음식   8\n",
       "4         목사님이 잘 하는 사람 선물 준대    전라  남      크리스마스    9\n",
       "...                       ...  ... ..         ...  ..\n",
       "374331  그러니까 이제 더 아프면 안돼 약속해    경상  여     엄마가 아파요  10\n",
       "374332               머리가 어지러워   경상  여          공부   6\n",
       "374333                아 빗나갔다    강원  남      오락실 게임   8\n",
       "374334        수민이가 이사가서 서운해요   수도권  남          친구   7\n",
       "374335           난 거북이를 키우고 싶  수도권  남         거북이   6\n",
       "\n",
       "[374336 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>음성인식결과</th>\n",
       "      <th>지역</th>\n",
       "      <th>성별</th>\n",
       "      <th>대화주제</th>\n",
       "      <th>나이</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>내일 또 얘기하자</td>\n",
       "      <td>수도권</td>\n",
       "      <td>여</td>\n",
       "      <td>학교</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>교복을 입고 왔어요</td>\n",
       "      <td>수도권</td>\n",
       "      <td>여</td>\n",
       "      <td>교복</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>나는 씩씩해요</td>\n",
       "      <td>수도권</td>\n",
       "      <td>여</td>\n",
       "      <td>소풍을 다녀와서</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>빨리 내일이 됐으면 좋겠다</td>\n",
       "      <td>수도권</td>\n",
       "      <td>여</td>\n",
       "      <td>삼촌댁에 놀러가기</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>같이 맞는 거야</td>\n",
       "      <td>수도권</td>\n",
       "      <td>여</td>\n",
       "      <td>삶과 죽음</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142358</th>\n",
       "      <td>나도 발레 배우는데</td>\n",
       "      <td>수도권</td>\n",
       "      <td>남</td>\n",
       "      <td>발레</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142359</th>\n",
       "      <td>유치원 때부터 배웠어</td>\n",
       "      <td>수도권</td>\n",
       "      <td>남</td>\n",
       "      <td>발레</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142360</th>\n",
       "      <td>다리를 모아야 돼</td>\n",
       "      <td>수도권</td>\n",
       "      <td>남</td>\n",
       "      <td>발레</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142361</th>\n",
       "      <td>무릎이 붙어야 하는 거야</td>\n",
       "      <td>수도권</td>\n",
       "      <td>남</td>\n",
       "      <td>발레</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142362</th>\n",
       "      <td>손을 위로 올리고 왼쪽 다리를 내밀어야 돼</td>\n",
       "      <td>수도권</td>\n",
       "      <td>남</td>\n",
       "      <td>발레</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1142363 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          음성인식결과   지역 성별       대화주제  나이\n",
       "0                      내일 또 얘기하자  수도권  여         학교   5\n",
       "1                     교복을 입고 왔어요  수도권  여         교복   5\n",
       "2                       나는 씩씩해요   수도권  여   소풍을 다녀와서   7\n",
       "3                빨리 내일이 됐으면 좋겠다   수도권  여  삼촌댁에 놀러가기   7\n",
       "4                       같이 맞는 거야  수도권  여      삶과 죽음   7\n",
       "...                          ...  ... ..        ...  ..\n",
       "1142358               나도 발레 배우는데  수도권  남         발레  10\n",
       "1142359              유치원 때부터 배웠어  수도권  남         발레  10\n",
       "1142360                다리를 모아야 돼  수도권  남         발레  10\n",
       "1142361            무릎이 붙어야 하는 거야  수도권  남         발레  10\n",
       "1142362  손을 위로 올리고 왼쪽 다리를 내밀어야 돼  수도권  남         발레  10\n",
       "\n",
       "[1142363 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_preprocessing(data, config):\n",
    "    breakpoint()\n",
    "    if config[\"balancing\"]:\n",
    "        label_counts = data[config[\"output\"]].value_counts()\n",
    "        min_count = label_counts.min()\n",
    "\n",
    "        resampled_data = pd.DataFrame()\n",
    "        for label in label_counts.index:\n",
    "            label_data = data[data[config[\"output\"]] == label]\n",
    "            resampled_label_data = label_data.sample(min_count, replace=False)\n",
    "\n",
    "            resampled_data = pd.concat(\n",
    "                [resampled_data, resampled_label_data], ignore_index=True\n",
    "            )\n",
    "\n",
    "        data = resampled_data.sample(frac=1).reset_index(drop=True)\n",
    "    else:\n",
    "        pass\n",
    "    print(\"Data Counts:\")\n",
    "    breakpoint()\n",
    "    for label in sorted(data[config[\"output\"]].unique()):\n",
    "        count = len(data[data[config[\"output\"]] == label])\n",
    "        print(f\"Label {label}: {count} samples\")\n",
    "\n",
    "    total_count = len(data)\n",
    "    print(f\"Total number of samples: {total_count}\")\n",
    "\n",
    "    return resampled_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
